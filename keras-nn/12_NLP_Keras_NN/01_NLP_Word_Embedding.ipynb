{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "labeled-harvey",
   "metadata": {},
   "source": [
    "### Word Embeddings -Keras\n",
    "\n",
    "Problems with One-Hot Encoded Feature Vector Approaches\n",
    "A potential drawback with one-hot encoded feature vector approaches such as N-Grams, bag of words and TF-IDF approach is that the feature vector for each document can be huge. For instance, if you have a half million unique words in your corpus and you want to represent a sentence that contains 10 words, your feature vector will be a half million dimensional one-hot encoded vector where only 10 indexes will have 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "architectural-landing",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "In word embeddings, every word is represented as an n-dimensional dense vector. The words that are similar will have similar vector. Word embeddings techniques such as GloVe and Word2Vec have proven to be extremely efficient for converting words into corresponding dense vectors. The vector size is small and none of the indexes in the vector is actually empty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-montgomery",
   "metadata": {},
   "source": [
    "### Implementation of Word Embedding with Keras\n",
    "> To implement word embeddings, the Keras library contains a layer called ``Embedding()``. The embedding layer is implemented in the form of a class in Keras and is normally used as a first layer in the sequential model for NLP tasks.\n",
    "\n",
    "[Read More](https://stats.stackexchange.com/questions/270546/how-does-keras-embedding-layer-work)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-wyoming",
   "metadata": {},
   "source": [
    "> Embedding(200, 32, input_length=50)\n",
    "\n",
    "* The first parameter in the embeddig layer is the size of the vocabulary or the **total number of unique words in a corpus**.\n",
    "* The second parameter is the number of the **dimensions for each word vector**. For instance, if you want each word vector to have 32 dimensions, you will specify 32 as the second parameter. \n",
    "* And finally, the third parameter is the **length of the input sentence**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-visiting",
   "metadata": {},
   "source": [
    "### Custom Word Embeddings\n",
    "> We are going to create our custom word embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cloudy-lunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import one_hot, Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outdoor-stage",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "public-drink",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    'This is an excellent movie',\n",
    "    'The move was fantastic I like it',\n",
    "    'You should watch it is brilliant',\n",
    "    'Exceptionally good',\n",
    "    'Wonderfully directed and executed I like it',\n",
    "    'Its a fantastic series',\n",
    "    'Never watched such a brillent movie',\n",
    "    'It is a Wonderful movie',\n",
    "    \"horrible acting\",\n",
    "    'waste of money',\n",
    "    'pathetic picture',\n",
    "    'It was very boring',\n",
    "    'I did not like the movie',\n",
    "    'The movie was horrible',\n",
    "    'I will not recommend',\n",
    "    'The acting is pathetic'\n",
    "]\n",
    "sentiments = np.array([1 if i< 8 else 0 for i in range(16)])\n",
    "sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aquatic-found",
   "metadata": {},
   "source": [
    "> The first `8` are positive `reviews` about the move and the last 8 are negative reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-bookmark",
   "metadata": {},
   "source": [
    "> `0` sentiment means a negative review about the movie and `1` is a positive review about the move. as we know the `Embedding()` layer takes `vocabulary` or number of `unique` words. We want to find the total number of `unique` words in the copus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "interstate-cause",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intensive-banana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_words = []\n",
    "for sent in corpus:\n",
    "    words = word_tokenize(sent)\n",
    "    for word in words:\n",
    "        all_words.append(word)\n",
    "len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dangerous-spotlight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = list(set(all_words))\n",
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crucial-shaft",
   "metadata": {},
   "source": [
    "> The Embedding layer expects the words to be in **numeric form**. Therefore, we need to convert the sentences in our corpus to numbers. One way to convert text to numbers is by using the ``one_hot`` function from the ``keras.preprocessing.text`` library. The function takes ``sentence`` and the ``total length of the vocabulary and returns the sentence in numeric form``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "continuous-three",
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_len = len(unique_words) + 5 ## we are just adding 5 to unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "boring-charger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[40, 12, 17, 45, 18],\n",
       " [17, 47, 48, 40, 13, 34, 28],\n",
       " [17, 30, 30, 28, 12, 5],\n",
       " [7, 31],\n",
       " [12, 17, 10, 3, 13, 34, 28],\n",
       " [1, 16, 40, 37],\n",
       " [43, 25, 45, 16, 10, 18],\n",
       " [28, 12, 16, 33, 18],\n",
       " [2, 18],\n",
       " [41, 33, 46],\n",
       " [40, 49],\n",
       " [28, 48, 44, 26],\n",
       " [13, 36, 19, 34, 17, 18],\n",
       " [17, 18, 48, 2],\n",
       " [13, 43, 19, 14],\n",
       " [17, 18, 12, 40]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentences = [one_hot(sent, voc_len) for sent in corpus]\n",
    "embedded_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-consensus",
   "metadata": {},
   "source": [
    "> The embedding layer expects sentences to be of equal size. However, our encoded sentences are of different sizes. One way to make all the sentences of uniform size is to increase the lenght of all the sentences and make it equal to the length of the largest sentence. Let's first find the largest sentence in our corpus and then we will increase the length of all the sentences to the length of the largest sentence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "advanced-exploration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = lambda sentence: len(word_tokenize(sentence))\n",
    "longest_sentence = max(corpus, key=word_count)\n",
    "len_longest_sentence = len(word_tokenize(longest_sentence))\n",
    "len_longest_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loving-recall",
   "metadata": {},
   "source": [
    "> We want to make all sentences have equal size, so the sentences that has length less than 7 we will fill the gaps of marking them `7` by 0 using `pad_sequences`. The first parameter is the list of **encoded sentences of unequal sizes**, the second parameter is the **size of the longest sentence** or the padding index, while the last parameter is **padding** where you specify post to add padding at the end of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "satisfactory-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded_sents = pad_sequences(embedded_sentences, len_longest_sentence, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "instructional-peeing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 12, 17, 45, 18,  0,  0],\n",
       "       [17, 47, 48, 40, 13, 34, 28],\n",
       "       [17, 30, 30, 28, 12,  5,  0],\n",
       "       [ 7, 31,  0,  0,  0,  0,  0],\n",
       "       [12, 17, 10,  3, 13, 34, 28],\n",
       "       [ 1, 16, 40, 37,  0,  0,  0],\n",
       "       [43, 25, 45, 16, 10, 18,  0],\n",
       "       [28, 12, 16, 33, 18,  0,  0],\n",
       "       [ 2, 18,  0,  0,  0,  0,  0],\n",
       "       [41, 33, 46,  0,  0,  0,  0],\n",
       "       [40, 49,  0,  0,  0,  0,  0],\n",
       "       [28, 48, 44, 26,  0,  0,  0],\n",
       "       [13, 36, 19, 34, 17, 18,  0],\n",
       "       [17, 18, 48,  2,  0,  0,  0],\n",
       "       [13, 43, 19, 14,  0,  0,  0],\n",
       "       [17, 18, 12, 40,  0,  0,  0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "athletic-bunch",
   "metadata": {},
   "source": [
    "### Creating a Simple Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "driven-friend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 7, 20)             1000      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                2256      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,273\n",
      "Trainable params: 3,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    tf.keras.layers.Embedding(voc_len, 20, input_length=len_longest_sentence),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(16, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-newton",
   "metadata": {},
   "source": [
    "> A Sequential model and add the ``Embedding`` layer as the first layer to the model. The length of the vocabulary is specified by the ``voc_len`` parameter. The dimension of each word vector will be ``20`` and the ``input_length`` will be the length of the longest sentence, which is ``7``. Next, the ``Embedding`` layer is flattened so that it can be directly used with the densely connected layer. Since it is a ``binary classification`` problem, we use the ``sigmoid`` function as the loss function at the dense layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-connecticut",
   "metadata": {},
   "source": [
    "### Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "useful-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=keras.optimizers.Adam(lr=1e-3), \n",
    "              loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=['accuracy']\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-badge",
   "metadata": {},
   "source": [
    "### Trainning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unexpected-gravity",
   "metadata": {},
   "source": [
    "> First we want to shuffle our datasets and then split them into train and test as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "biological-middle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 12, 17, 45, 18,  0,  0,  1],\n",
       "       [17, 47, 48, 40, 13, 34, 28,  1],\n",
       "       [17, 30, 30, 28, 12,  5,  0,  1],\n",
       "       [ 7, 31,  0,  0,  0,  0,  0,  1],\n",
       "       [12, 17, 10,  3, 13, 34, 28,  1],\n",
       "       [ 1, 16, 40, 37,  0,  0,  0,  1],\n",
       "       [43, 25, 45, 16, 10, 18,  0,  1],\n",
       "       [28, 12, 16, 33, 18,  0,  0,  1],\n",
       "       [ 2, 18,  0,  0,  0,  0,  0,  0],\n",
       "       [41, 33, 46,  0,  0,  0,  0,  0],\n",
       "       [40, 49,  0,  0,  0,  0,  0,  0],\n",
       "       [28, 48, 44, 26,  0,  0,  0,  0],\n",
       "       [13, 36, 19, 34, 17, 18,  0,  0],\n",
       "       [17, 18, 48,  2,  0,  0,  0,  0],\n",
       "       [13, 43, 19, 14,  0,  0,  0,  0],\n",
       "       [17, 18, 12, 40,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.column_stack([padded_sents, sentiments])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "amber-playlist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[28, 48, 44, 26,  0,  0,  0,  0],\n",
       "       [17, 18, 12, 40,  0,  0,  0,  0],\n",
       "       [13, 36, 19, 34, 17, 18,  0,  0],\n",
       "       [13, 43, 19, 14,  0,  0,  0,  0],\n",
       "       [43, 25, 45, 16, 10, 18,  0,  1],\n",
       "       [12, 17, 10,  3, 13, 34, 28,  1],\n",
       "       [17, 47, 48, 40, 13, 34, 28,  1],\n",
       "       [ 7, 31,  0,  0,  0,  0,  0,  1],\n",
       "       [28, 12, 16, 33, 18,  0,  0,  1],\n",
       "       [40, 49,  0,  0,  0,  0,  0,  0],\n",
       "       [41, 33, 46,  0,  0,  0,  0,  0],\n",
       "       [ 1, 16, 40, 37,  0,  0,  0,  1],\n",
       "       [17, 30, 30, 28, 12,  5,  0,  1],\n",
       "       [40, 12, 17, 45, 18,  0,  0,  1],\n",
       "       [17, 18, 48,  2,  0,  0,  0,  0],\n",
       "       [ 2, 18,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.shuffle(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "injured-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, random_state=33, test_size= .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "enclosed-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[:][:, :7]\n",
    "X_test = test[:][:, :7]\n",
    "\n",
    "y_test = test[:][:,-1]\n",
    "y_train = train[:][:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "placed-parish",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/2 - 0s - loss: 0.6779 - accuracy: 0.8333 - val_loss: 0.6896 - val_accuracy: 0.7500\n",
      "Epoch 2/10\n",
      "2/2 - 0s - loss: 0.6726 - accuracy: 0.9167 - val_loss: 0.6906 - val_accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "2/2 - 0s - loss: 0.6682 - accuracy: 0.9167 - val_loss: 0.6911 - val_accuracy: 0.5000\n",
      "Epoch 4/10\n",
      "2/2 - 0s - loss: 0.6638 - accuracy: 0.9167 - val_loss: 0.6912 - val_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "2/2 - 0s - loss: 0.6595 - accuracy: 0.9167 - val_loss: 0.6915 - val_accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "2/2 - 0s - loss: 0.6551 - accuracy: 0.9167 - val_loss: 0.6912 - val_accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "2/2 - 0s - loss: 0.6508 - accuracy: 0.9167 - val_loss: 0.6905 - val_accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "2/2 - 0s - loss: 0.6464 - accuracy: 0.9167 - val_loss: 0.6895 - val_accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "2/2 - 0s - loss: 0.6419 - accuracy: 0.9167 - val_loss: 0.6885 - val_accuracy: 0.7500\n",
      "Epoch 10/10\n",
      "2/2 - 0s - loss: 0.6372 - accuracy: 0.9167 - val_loss: 0.6876 - val_accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x247ea82d850>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 10\n",
    "VALIDATION_SET = (X_test, y_test)\n",
    "model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=2, validation_data=VALIDATION_SET)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "drawn-limitation",
   "metadata": {},
   "source": [
    "### Making Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "medium-straight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.]], dtype=float32),\n",
       " array([0, 0, 0, 1]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict(X_test[:])), y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "stainless-perry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6876 - accuracy: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6875579953193665, 0.75]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "another-facility",
   "metadata": {},
   "source": [
    "> Those are the basics of `custom word embeddings`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-october",
   "metadata": {},
   "source": [
    "### Loading Pretrained Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amended-holmes",
   "metadata": {},
   "source": [
    "[Doccs](https://stackabuse.com/python-for-nlp-word-embeddings-for-deep-learning-in-keras/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "photographic-testimony",
   "metadata": {},
   "source": [
    "> Several types of pretrained word embeddings exist, however we will be using the `GloVe` word embeddings from Stanford NLP since it is the most famous one and commonly used and can be downloaded **[Here](https://nlp.stanford.edu/projects/glove/)**.\n",
    "\n",
    "Im going to download the `Glove.6B.zip` which is `822MB`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-eclipse",
   "metadata": {},
   "source": [
    "> From our `custom` word embedding we have used `one_hot` function to convert text to `vectors` another approach is to use the [Tokenizer](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/text/Tokenizer) from `keras.preprocessing.text`. All we have to do is to pass the corpus to the `fit_on_text` method and to get the number of unique words we can count the length of the `word_index` and add `1` to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "surprising-hazard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is an excellent movie',\n",
       " 'The move was fantastic I like it',\n",
       " 'You should watch it is brilliant',\n",
       " 'Exceptionally good',\n",
       " 'Wonderfully directed and executed I like it',\n",
       " 'Its a fantastic series',\n",
       " 'Never watched such a brillent movie',\n",
       " 'It is a Wonderful movie',\n",
       " 'horrible acting',\n",
       " 'waste of money',\n",
       " 'pathetic picture',\n",
       " 'It was very boring',\n",
       " 'I did not like the movie',\n",
       " 'The movie was horrible',\n",
       " 'I will not recommend',\n",
       " 'The acting is pathetic']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "injured-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aquatic-brighton",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc_len = len(tokenizer.word_index) + 1\n",
    "voc_len "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-window",
   "metadata": {},
   "source": [
    "### Converting sentences to their numeric part.\n",
    ">To convert sentences to their numeric counterpart, call the `texts_to_sequences` function and pass it the whole corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "general-flavor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[14, 3, 15, 16, 1],\n",
       " [4, 17, 6, 9, 5, 7, 2],\n",
       " [18, 19, 20, 2, 3, 21],\n",
       " [22, 23],\n",
       " [24, 25, 26, 27, 5, 7, 2],\n",
       " [28, 8, 9, 29],\n",
       " [30, 31, 32, 8, 33, 1],\n",
       " [2, 3, 8, 34, 1],\n",
       " [10, 11],\n",
       " [35, 36, 37],\n",
       " [12, 38],\n",
       " [2, 6, 39, 40],\n",
       " [5, 41, 13, 7, 4, 1],\n",
       " [4, 1, 6, 10],\n",
       " [5, 42, 13, 43],\n",
       " [4, 11, 3, 12]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_sentences = tokenizer.texts_to_sequences(corpus)\n",
    "embedded_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decimal-seafood",
   "metadata": {},
   "source": [
    "### Finding the number of the longest sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "integral-hotel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_count = lambda sentence: len(word_tokenize(sentence))\n",
    "longest_sentence = max(corpus, key=word_count)\n",
    "length_long_sentence = len(word_tokenize(longest_sentence))\n",
    "length_long_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-thong",
   "metadata": {},
   "source": [
    "### Padding sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "institutional-rehabilitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14,  3, 15, 16,  1,  0,  0],\n",
       "       [ 4, 17,  6,  9,  5,  7,  2],\n",
       "       [18, 19, 20,  2,  3, 21,  0],\n",
       "       [22, 23,  0,  0,  0,  0,  0],\n",
       "       [24, 25, 26, 27,  5,  7,  2],\n",
       "       [28,  8,  9, 29,  0,  0,  0],\n",
       "       [30, 31, 32,  8, 33,  1,  0],\n",
       "       [ 2,  3,  8, 34,  1,  0,  0],\n",
       "       [10, 11,  0,  0,  0,  0,  0],\n",
       "       [35, 36, 37,  0,  0,  0,  0],\n",
       "       [12, 38,  0,  0,  0,  0,  0],\n",
       "       [ 2,  6, 39, 40,  0,  0,  0],\n",
       "       [ 5, 41, 13,  7,  4,  1,  0],\n",
       "       [ 4,  1,  6, 10,  0,  0,  0],\n",
       "       [ 5, 42, 13, 43,  0,  0,  0],\n",
       "       [ 4, 11,  3, 12,  0,  0,  0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_sents = pad_sequences(embedded_sentences, length_long_sentence, padding=\"post\" )\n",
    "padded_sents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greek-zoning",
   "metadata": {},
   "source": [
    "### Loading the `GloVe` \n",
    "> load the GloVe word embeddings and then create our embedding matrix that contains the words in our corpus and their corresponding values from GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "frequent-subject",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dictionary = dict() ## This will store word embeddings\n",
    "\n",
    "with open(r\"C:\\Users\\crisp\\Downloads\\glove.6B\\glove.6B.100d.txt\", encoding=\"utf8\") as glove_file:\n",
    "    for line in glove_file:\n",
    "        records = line.split()\n",
    "        word = records[0]\n",
    "        vectors = np.asarray(records[1:], dtype=np.float32)\n",
    "        embeddings_dictionary[word] = vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "agricultural-reporter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n",
       "       -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\n",
       "        0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\n",
       "       -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\n",
       "        0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\n",
       "       -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\n",
       "        0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\n",
       "        0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\n",
       "       -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\n",
       "       -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\n",
       "       -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\n",
       "       -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\n",
       "       -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\n",
       "       -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\n",
       "       -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\n",
       "        0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\n",
       "       -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dictionary[\"the\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tropical-wagon",
   "metadata": {},
   "source": [
    "> The dictionary `embeddings_dictionary` now contains words and corresponding **`GloVe`** embeddings for all the words.\n",
    "\n",
    "> We want the word embeddings for only those words that are present in our corpus. We will create a two dimensional numpy array of `44` (size of vocabulary) rows and `100` columns. The array will initially contain zeros. The array will be named as `embedding_matrix`.\n",
    "\n",
    "> Next, we will iterate through each word in our corpus by traversing the `word_tokenizer.word_index` dictionary that contains our words and their corresponding index.\n",
    "\n",
    "> Each word will be passed as key to the `embedding_dictionary` to retrieve the corresponding `100` dimensional vector for the word. The `100` dimensional vector will then be stored at the corresponding index of the word in the `embedding_matrix`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "spanish-credits",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.38251001  0.14821     0.60601002 ...  0.058921    0.091112\n",
      "   0.47283   ]\n",
      " [-0.30664     0.16821     0.98510998 ... -0.38775     0.36916\n",
      "   0.54521   ]\n",
      " ...\n",
      " [ 0.30449    -0.19628     0.20225    ... -0.18385001 -0.12432\n",
      "   0.27467999]\n",
      " [-0.26703     0.44911     0.55478001 ... -0.87247002  0.83828002\n",
      "   0.465     ]\n",
      " [-0.57547998 -0.043236   -0.1972     ... -0.10507     0.26554999\n",
      "   0.32192999]]\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((voc_len, 100))\n",
    "#print(embedding_matrix)\n",
    "\n",
    "for word, index in tokenizer.word_index.items():\n",
    "#     print(word, index)\n",
    "    embedding_vect = embeddings_dictionary.get(word)\n",
    "    \n",
    "    if embedding_vect is not None:\n",
    "        embedding_matrix[index] = embedding_vect\n",
    "print(embedding_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-chaos",
   "metadata": {},
   "source": [
    "> Our `embedding_matrix` now contains pretrained word embeddings for the words in our corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-ballet",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "square-priority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 7, 100)            4400      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 700)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 701       \n",
      "=================================================================\n",
      "Total params: 5,101\n",
      "Trainable params: 701\n",
      "Non-trainable params: 4,400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(voc_len, 100, weights=[embedding_matrix], \n",
    "              input_length=length_long_sentence, trainable=False),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-funeral",
   "metadata": {},
   "source": [
    "> The script remains the same, except for the embedding layer. Here in the embedding layer, the first parameter is the size of the vacabulary. The second parameter is the vector dimension of the output vector. Since we are using pretrained word embeddings that contain 100 dimensional vector, we set the vector dimension to 100.\n",
    "\n",
    "> Another very important attribute of the `Embedding()` layer that we did not use in the last section is `weights`. You can pass your pretrained embedding matrix as default `weights` to the `weights` parameter. And since we are not training the embedding layer, the `trainable` attribute has been set to `False`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporated-format",
   "metadata": {},
   "source": [
    "### Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "institutional-beaver",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "    loss = keras.losses.BinaryCrossentropy(),\n",
    "    metrics =[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-concentration",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "common-sheet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7187 - accuracy: 0.5625\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.6889 - accuracy: 0.6875\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6614 - accuracy: 0.6250\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6361 - accuracy: 0.7500\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.6127 - accuracy: 0.6875\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5908 - accuracy: 0.8125\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5703 - accuracy: 0.8750\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5508 - accuracy: 0.9375\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5322 - accuracy: 0.9375\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5143 - accuracy: 0.9375\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4971 - accuracy: 0.9375\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4805 - accuracy: 0.9375\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4645 - accuracy: 0.9375\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4491 - accuracy: 0.9375\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4343 - accuracy: 0.9375\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4200 - accuracy: 0.9375\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4063 - accuracy: 0.9375\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3932 - accuracy: 0.9375\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3807 - accuracy: 0.9375\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3687 - accuracy: 0.9375\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3572 - accuracy: 0.9375\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3463 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3358 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3257 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3161 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.3069 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2980 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.2894 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2812 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2733 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.2657 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2584 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2514 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2446 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2382 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2319 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.2259 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2201 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2146 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2092 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2041 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1991 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1944 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1898 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1853 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1810 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1769 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1729 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1691 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1653 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1617 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1583 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1549 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1517 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1485 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1455 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1426 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1397 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1370 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1343 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.1317 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1292 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1268 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1244 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1222 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1199 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1178 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1157 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1137 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1117 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1098 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1079 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1061 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1043 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1026 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.1010 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0993 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0978 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0962 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0947 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0933 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0918 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0904 - accuracy: 1.0000\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0891 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0878 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0865 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0852 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0840 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0828 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0816 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0793 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0783 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0772 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0761 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0751 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0741 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0731 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0722 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x247ea782c70>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_sents, sentiments, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-discharge",
   "metadata": {},
   "source": [
    "### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "administrative-magic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07033342123031616, 1.0]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(padded_sents, sentiments, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elect-heritage",
   "metadata": {},
   "source": [
    "### Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "veterinary-campus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.9590082],\n",
       "        [0.9785887]], dtype=float32),\n",
       " array([1, 1]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(padded_sents[:2]), sentiments[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-commercial",
   "metadata": {},
   "source": [
    "#### Creating a function that sentiments 7-word review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "foster-motorcycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The review is:  Negative\n"
     ]
    }
   ],
   "source": [
    "class LongSent(Exception):\n",
    "    pass\n",
    "def predictSentiment(sent):\n",
    "    embedded_sentence = tokenizer.texts_to_sequences([sent])\n",
    "    \n",
    "    try:\n",
    "        if len(embedded_sentence[0]) > 7:\n",
    "            raise LongSent(\"The review is too long\")   \n",
    "        padded_sent = pad_sequences(embedded_sentence, length_long_sentence, padding=\"post\" )\n",
    "        sent_index_predicted = np.round(model.predict(padded_sent))\n",
    "        \n",
    "        print(\"The review is: \", [\"Negative\", \"Positive\"][int(sent_index_predicted[0][0])])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "predictSentiment(\"I love this movie.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-knowing",
   "metadata": {},
   "source": [
    "> **In NLP** we need more data to train our model as we can see this model is predicting `wrongly`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-enclosure",
   "metadata": {},
   "source": [
    "### Word Embeddings with Keras Functional API\n",
    "* It is extremely important to know how Keras Functional API works. Most of the advanced deep learning models involving multiple inputs and outputs use the Functional API.\n",
    "* The rest of the script remains similar as it was in the last section. The only change will be in the development of a deep learning model. Let's implement the same deep learning model as we implemented in the last section with Keras Functional API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "honest-potato",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "presidential-documentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_inputs = Input(shape=(length_long_sentence,))\n",
    "\n",
    "embedding = keras.layers.Embedding(voc_len, 100, weights=[embedding_matrix],\n",
    "                      input_length=length_long_sentence,\n",
    "                      trainable=False)(deep_inputs)\n",
    "flatten = keras.layers.Flatten()(embedding)\n",
    "hidden = keras.layers.Dense(1, activation='sigmoid')(flatten)\n",
    "model = Model(inputs=deep_inputs, outputs=hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thorough-garden",
   "metadata": {},
   "source": [
    "> In the Keras `Functional API`, you have to define the `input layer` separately before the `embedding layer`. In the input, layer you have to simply pass the length of input vector. To specify that previous layer as input to the next layer, the previous layer is passed as a parameter inside the parenthesis, at the end of the next layer.\n",
    "\n",
    "> For instance, in the above script, you can see that `deep_inputs` is passed as parameter at the end of the embedding layer. Similarly, `embedding` is passed as input at the end of the `Flatten()` layer and so on.\n",
    "\n",
    "> Finally, in the `Model()`, you have to pass the input layer, and the final output layer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
