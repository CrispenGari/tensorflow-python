{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0z0WVe5LetML"
   },
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zuk6OHNSeve3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\crisp\\\\Documents\\\\anaconda3\\\\Lib\\\\site-packages\\\\~umpy\\\\.libs\\\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install -q tensorflow tensorflow-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6cikfadSew47"
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "U9grIZb9eyrT"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow_datasets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-da026df7efa9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow_datasets\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtfds\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_datasets'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZxeO5C5pez4W"
   },
   "source": [
    "### Checking datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_h1KAxde25T",
    "outputId": "dd791cfc-0ddd-4dcb-d72e-15a4478d39e0"
   },
   "outputs": [],
   "source": [
    "print(tfds.list_builders())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NSHwNJ5ie3ea"
   },
   "source": [
    "### Getting data Infomation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YfHKJNp6e7qZ",
    "outputId": "7391cff5-f452-423d-83f0-d5443f965279"
   },
   "outputs": [],
   "source": [
    "builder = tfds.builder('rock_paper_scissors')\n",
    "info = builder.info\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VUxQNMJpe8J0"
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LfI1BqNee_GT"
   },
   "outputs": [],
   "source": [
    "train = tfds.load(name='rock_paper_scissors', split=\"train\")\n",
    "test = tfds.load(name='rock_paper_scissors', split='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oo9cYBiUhgzL"
   },
   "source": [
    "### Iterating over data\n",
    "> To iterate over a tensorflow dataset we do it as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "isR5nRe3gtp3",
    "outputId": "c5d368c2-5806-4101-df63-17eafac7092c"
   },
   "outputs": [],
   "source": [
    "for data in train:\n",
    "  print(data['image'], data['label'])\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oO_KP18lh1Rk"
   },
   "source": [
    "### Creating a Numpy data\n",
    "> We are going to scale our data and convert it to a nummpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Sui-N2hhE-8"
   },
   "outputs": [],
   "source": [
    "train_images = np.array([data['image'].numpy()/255 for data in train])\n",
    "train_labels =np.array([data['label'].numpy() for data in train])\n",
    "test_image = np.array([data['image'].numpy()/255   for data in test])\n",
    "test_labels = np.array([data['label'].numpy() for data in test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "coydWR5FjMoX",
    "outputId": "0b884de2-31ea-4912-801d-2d576b8b518e"
   },
   "outputs": [],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YjUpcC6vjo6_"
   },
   "source": [
    "### Class Names\n",
    "0 - Rock\n",
    "\n",
    "1 - Paper\n",
    "\n",
    "2 - Scissors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wfSaxWgThFF2"
   },
   "outputs": [],
   "source": [
    "class_names = np.array([\"rock\", \"paper\", \"scissor\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cjdKvufNfBi2"
   },
   "source": [
    "### Creating a NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_S6hEaT-fEkF",
    "outputId": "93913bad-203f-4001-bc60-a452de8d55c1"
   },
   "outputs": [],
   "source": [
    "input_shape = train_images[0].shape\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gj5gZ5i2kJFi",
    "outputId": "e940012e-f0ca-45e5-e0f2-399e77e922cb"
   },
   "outputs": [],
   "source": [
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), input_shape=input_shape, activation='relu'),\n",
    "    keras.layers.MaxPool2D((3,3)) ,\n",
    "    keras.layers.Conv2D(64, (2, 2), activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Conv2D(64, (2, 2), activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LvEJSTvVlXJU"
   },
   "source": [
    "### Combiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RYYk9qHalRKQ"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=.0001),\n",
    "    metrics=[\"accuracy\"],\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kj-Xb2F6mkO2"
   },
   "source": [
    "### Fitting the ModeL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G61NVC4hlWAl",
    "outputId": "2f89b1f4-53a7-4957-a2cd-ad82663470ae"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "BATCH_SIZE = 4\n",
    "VALIDATION_SET = (test_image, test_labels)\n",
    "history = model.fit(train_images, train_labels, epochs=EPOCHS, validation_data=VALIDATION_SET, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zM2IVzrGyRT2"
   },
   "source": [
    "### Model Evaluation Conclusion\n",
    "Our model is performing perfect. The loss on the train_set is almost 0 as well as the validation loss. The accuracy on the train set is `100%` compared to `83%` accuracy on the test set.\n",
    "\n",
    "> The model is just overtraining but giving us good results on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCR7k8Aoy6h7"
   },
   "source": [
    "### Making Predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_zDtH2MHlWEC",
    "outputId": "b74c96b8-98a5-4790-c7f1-ff9c12e159c9"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_image[:10])\n",
    "for i, j in zip(predictions, test_labels[:10]):\n",
    "  print(class_names[np.argmax(i)],\"-------->\", class_names[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b83QOHCV0IVn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TWq4DlDc0CLs"
   },
   "source": [
    "### Tunning Hyper Parameters -- Keras-Tunner\n",
    "* [Docs](https://www.tensorflow.org/tutorials/keras/keras_tuner)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cl6I5Mt70V82"
   },
   "source": [
    "### Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EkJ24NeVlWKP",
    "outputId": "e17aeb9d-24f0-46a8-ef1b-5629d6359796"
   },
   "outputs": [],
   "source": [
    "pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pZko7sZ_0oHz"
   },
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OPoGe010jq4"
   },
   "outputs": [],
   "source": [
    "import kerastuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o6H7Kfxi0qTJ"
   },
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "\n",
    "  model = keras.Sequential()\n",
    "  #   we want the model to find the best unit and the activation function for the first layer for us\n",
    "  model.add(keras.layers.Conv2D(hp.Int('units',  min_value=32, max_value=512, step=32),(3, 3), \n",
    "                                input_shape=input_shape, activation=hp.Choice('activation-fn',values=['relu', 'sgd'])))\n",
    "  \n",
    "  model.add(keras.layers.MaxPool2D((3,3)))\n",
    "  model.add(keras.layers.Conv2D(64, (2, 2), activation='relu'))\n",
    "  model.add(keras.layers.MaxPool2D((2,2)))\n",
    "  model.add(keras.layers.Conv2D(64, (2, 2), activation='relu'))\n",
    "  model.add(keras.layers.MaxPool2D((2,2)))\n",
    "  model.add(keras.layers.Flatten())\n",
    "  model.add(keras.layers.Dense(64, activation='relu'))\n",
    "  model.add(keras.layers.Dense(32, activation='relu'))\n",
    "  model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JA-izSwo2e_a",
    "outputId": "55aa4da7-bf0b-49e8-b0d3-442d3a27f9ce"
   },
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4RDa3RWm3LzC",
    "outputId": "a3c6deb7-9ae0-4d1b-f9fd-1ee9f3761e9f"
   },
   "outputs": [],
   "source": [
    "tuner.search(train_images, train_labels, validation_data=VALIDATION_SET, epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlEHL9V55nVZ"
   },
   "source": [
    "> That's basically how the `kerastunner` works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8X1FkBXi35Bn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TensorFlowDataSets-RPS.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
