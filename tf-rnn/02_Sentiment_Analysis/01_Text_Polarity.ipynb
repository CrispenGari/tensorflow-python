{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-talent",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-patrol",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sharing-polymer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os, re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "hazardous-rebecca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1,\n",
       "       '@ChargerJenn Thx for answering so quick,I was afraid I was gonna crash twitter with all the spamming I did 2 RR..sorry bout that '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.iloc[2].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vanilla-nature",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "* Removing punctuations\n",
    "* Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "settled-teacher",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = df[\"polarity\"].values\n",
    "text = df['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "physical-mining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'a', 'aa', ..., 'zythum', 'Zyzomys', 'Zyzzogeton'],\n",
       "      dtype='<U24')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_words = np.array([word for word in nltk.corpus.words.words('en')])\n",
    "english_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "starting-marina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@ChargerJenn Thx for answering so quick,I was afraid I was gonna crash twitter with all the spamming I did 2 RR..sorry bout that '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = text[2]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "tired-carolina",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sent(sent):\n",
    "    a = re.sub(r'[^a-zA-Z]', ' ', sent)\n",
    "    b = re.sub(r'\\s+', ' ', a).strip().lower()\n",
    "    return b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "polar-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_sents = []\n",
    "for sent in text:\n",
    "    cleaned_sents.append(clean_sent(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "natural-former",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kconsidder you never tweet',\n",
       " 'sick today coding from the couch',\n",
       " 'chargerjenn thx for answering so quick i was afraid i was gonna crash twitter with all the spamming i did rr sorry bout that',\n",
       " 'wii fit says i ve lost pounds since last time',\n",
       " 'mrkinetik not a thing i don t really have a life']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_sents[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "prostate-valentine",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500000, 500000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_sents), len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "diagnostic-atlas",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "drawn-essay",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 250275, 1: 249725})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-orientation",
   "metadata": {},
   "source": [
    "### Create ``Word Vectors``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-basket",
   "metadata": {},
   "source": [
    "> Find number of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "therapeutic-trunk",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "for sent in cleaned_sents:\n",
    "    words = word_tokenize(sent)\n",
    "    for word in words:\n",
    "        counter[word] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adjusted-threshold",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272544"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_words = len(counter)\n",
    "unique_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "surprising-husband",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sized-institute",
   "metadata": {},
   "source": [
    "> Splitting `test` and `train` sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "obvious-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_sents, targets, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "informed-programmer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bengrossman utoh they moved you up an hour bummer i can t get down there that fast break a leg',\n",
       " 'nite folk i only got hours of sleep last night so i might sleep before jimmyfallon is over maybe']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-celebrity",
   "metadata": {},
   "source": [
    "> Create a `word_index` from the `test` data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "decreased-bandwidth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_preprocessing.text.Tokenizer at 0x1b71e519a90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(num_words=unique_words, oov_token=\"<OOV>\" )\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "handed-stadium",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indices = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-tractor",
   "metadata": {},
   "source": [
    "> Creating a `decord` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "foreign-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_indices_reversed = dict({(value, key) for (key, value) in word_indices.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "entire-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decord_text(sent):\n",
    "    return \" \".join([word_indices_reversed[i] for i in sent])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "warming-arthur",
   "metadata": {},
   "source": [
    "> Creating `word_tokens` from the `copra`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "revised-stomach",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tokens = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_tokens = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "subject-fighter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75395, 75396, 77, 1383, 9, 32, 97, 378, 1210, 2, 31, 14, 36, 164, 71, 18, 724, 539, 5, 1276]\n"
     ]
    }
   ],
   "source": [
    "print(X_train_tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quiet-button",
   "metadata": {},
   "source": [
    "> Decording the first `sent`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "pursuant-demand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bengrossman utoh they moved you up an hour bummer i can t get down there that fast break a leg'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decord_text(X_train_tokens[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-cannon",
   "metadata": {},
   "source": [
    "> Padd `suquencing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "closed-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words_in_a_sent = 100\n",
    "X_train_tokens_padded = pad_sequences(X_train_tokens, maxlen=max_words_in_a_sent, truncating='post', padding='post' )\n",
    "X_test_tokens_padded = pad_sequences(X_test_tokens, maxlen=max_words_in_a_sent, truncating='post', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cheap-equilibrium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100, 100, 100, 100, 100, "
     ]
    }
   ],
   "source": [
    "for sent in X_train_tokens[:5]:\n",
    "    print(len(sent), end=', ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-filename",
   "metadata": {},
   "source": [
    "> Creating a `Neural` Network.\n",
    "\n",
    "```python\n",
    "\n",
    "        [EmbedingLayer]\n",
    "               |-------\n",
    "            [LSTM]     | Bidirectional (backward = LSTM)\n",
    "               |<------       \n",
    "            [LSTM]     | Bidirectional (backward = GRU)\n",
    "               |-------\n",
    "            [LSTM] \n",
    "               |\n",
    "    [GlobalAveragePooling1D]\n",
    "               |\n",
    "            [Dense]\n",
    "               |\n",
    "            [Dense]\n",
    "               |\n",
    "            [Dense]\n",
    "            /    \\\n",
    "       (polite)  (rude)\n",
    "            \n",
    "            \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "attractive-basement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "weekly-casino",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_10 (Embedding)     (None, 100, 64)           17442816  \n",
      "_________________________________________________________________\n",
      "bidirectional_layer_1 (Bidir (None, 100, 256)          197632    \n",
      "_________________________________________________________________\n",
      "bidirectional_layer_2 (Bidir (None, 100, 128)          144000    \n",
      "_________________________________________________________________\n",
      "lstm_last_layer (LSTM)       (None, 32)                20608     \n",
      "_________________________________________________________________\n",
      "flatten_layer (Flatten)      (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_layer_1 (Dense)        (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "output_dense_layer (Dense)   (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 17,807,233\n",
      "Trainable params: 17,807,233\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "forward_layer_1 = keras.layers.LSTM(128, return_sequences=True, name=\"forward_layer_1\",\n",
    "                                   dropout=.5\n",
    "                                   )\n",
    "backward_layer_1 = keras.layers.LSTM(128, activation='relu', return_sequences=True, \n",
    "                                     go_backwards=True, name=\"backward_layer_1\",\n",
    "                                    dropout=.5\n",
    "                                    )\n",
    "forward_layer_2 = keras.layers.LSTM(64, return_sequences=True, \n",
    "                                    dropout = .5,\n",
    "                                    name=\"forward_layer_2\",\n",
    "                                   )\n",
    "backward_layer_2 = keras.layers.GRU(64, activation='relu', return_sequences=True, go_backwards=True,\n",
    "                                    dropout = .5,\n",
    "                                    name=\"backward_layer_2\"\n",
    "                                   )\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Embedding(input_dim=unique_words, output_dim=64, input_length=max_words_in_a_sent),\n",
    "    keras.layers.Bidirectional(forward_layer_1,\n",
    "                                    backward_layer = backward_layer_1\n",
    "                                   ,name=\"bidirectional_layer_1\"),\n",
    "    keras.layers.Bidirectional(forward_layer_2,\n",
    "                                backward_layer = backward_layer_2,\n",
    "                                name=\"bidirectional_layer_2\"),\n",
    "    keras.layers.LSTM(32, name=\"lstm_last_layer\"),\n",
    "    keras.layers.Flatten(name=\"flatten_layer\"),\n",
    "    keras.layers.Dense(64, activation='tanh', name=\"dense_layer_1\"),\n",
    "    keras.layers.Dense(1, activation='sigmoid', name=\"output_dense_layer\")\n",
    "], name=\"model_sequential\")\n",
    "model.compile(\n",
    "    loss = keras.losses.binary_crossentropy,\n",
    "    optimizer = keras.optimizers.Adam(),\n",
    "    metrics=[\"acc\"]\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "organized-villa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "declared-forest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 689/2500 [=======>......................] - ETA: 56:01 - loss: 0.6933 - acc: 0.5002"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-5318a88d3b28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                               )\n\u001b[1;32m----> 5\u001b[1;33m history = model.fit(X_train_tokens_padded, y_train, epochs=10, verbose=1, validation_split=.2, batch_size=128,\n\u001b[0m\u001b[0;32m      6\u001b[0m          callbacks=[early_stopping])\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss',\n",
    "                                                patience=3,\n",
    "                                                verbose=0\n",
    "                                              )\n",
    "history = model.fit(X_train_tokens_padded, y_train, epochs=10, verbose=1, validation_split=.2, batch_size=128,\n",
    "         callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transsexual-cambodia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BidirectionaLayer(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def call(self, x):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cross-volume",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-chile",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(keras.Model):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-hybrid",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organic-response",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "human-tablet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
